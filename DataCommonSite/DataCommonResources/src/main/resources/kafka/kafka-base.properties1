#kafka\u7684\u57FA\u7840\u914D\u7F6E

#kafka broker\u5217\u8868
bootstrap.servers=172.16.1.121:9092,172.16.1.122:9092,172.16.1.123:9092

#\u6D88\u8D39\u8005\u914D\u7F6E

#If true the consumer's offset will be periodically committed in the background.
#default true
enable.auto.commit=true

#The frequency in milliseconds that the consumer offsets are auto-committed to Kafka if <code>enable.auto.commit</code> is set to <code>true</code>.
#default 5000
auto.commit.interval.ms=5000

#What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server (e.g. because that data has been deleted):
# earliest: automatically reset the offset to the earliest offset
# latest: automatically reset the offset to the latest offset
# none: throw exception to the consumer if no previous offset is found for the consumer's group
#anything else: throw exception to the consumer.
#default latest
auto.offset.reset=earliest

key.deserializer=org.apache.kafka.common.serialization.StringDeserializer

value.deserializer=org.apache.kafka.common.serialization.StringDeserializer



#\u751F\u4EA7\u8005\u914D\u7F6E
#The producer will attempt to batch records together into fewer requests whenever multiple records are being sent to the same partition. This helps performance on both the client and the server. This configuration controls the default batch size in bytes.
#default 16384
batch.size=16384

acks=all

#The compression type for all data generated by the producer. The default is none (i.e. no compression). Valid values are none, gzip, snappy, or lz4. Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio (more batching means better compression).
#default none
#compression.type