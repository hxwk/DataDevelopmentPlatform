<spark-task-def id="">
    <inputs>
        <input id="11" type="InputHiveSql" inputIds="">
            <params>
                <param name="sql" value="select * from prod_analysis.kmeans"/>
            </params>
        </input>
    </inputs>
    <preprocess>
        <process id="21" type="PreprocessSelect" inputIds="11">
            <params>
                <param name="colNames" value="x,y,z,kclass"/>
            </params>
        </process>
    </preprocess>
    <algorithms>
        <algorithm name="name" type="AlgorithmRF" action="" inputIds="21">
            <params>
                <param name="saveTo" value="model/RandomForest"/>
                <param name="impurity" value="gini"/>
                <param name="maxBins" value="5"/>
                <param name="minInstancePerNode" value="1"/>
                <param name="maxDepth" value="7"/>
                <param name="action" value="AUTO_TRAINING"/>
                <param name="seed" value="100"/>
                <param name="featureCols" value="x,y,z"/>
                <param name="labelCol" value="kclass"/>
            </params>
        </algorithm>
        <algorithm name="name" type="AlgorithmRF" action="" inputIds="21">
            <params>
                <param name="saveTo" value="model/RandomForest"/>
                <param name="action" value="PREDICTING"/>
                <param name="featureCols" value="x,y,z"/>
            </params>
        </algorithm>
    </algorithms>
</spark-task-def>